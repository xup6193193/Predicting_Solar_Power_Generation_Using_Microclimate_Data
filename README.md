
# AI CUP 2024 - Predicting Solar Power Generation Using Microclimate Data

## Team Information

- **Team Name**: TEAM_5709  
- **Performance**:  
  - **Private Leaderboard Score**: 310,872.06  
  - **Private Leaderboard Rank**: 1st Place
   ![Award](https://github.com/xup6193193/Predicting_Solar_Power_Generation_Using_Microclimate_Data/blob/main/7fbdbf_fbcb57db75e54e0dad434e394b3df0cc~mv2.webp)
   ![Award](https://github.com/xup6193193/Predicting_Solar_Power_Generation_Using_Microclimate_Data/blob/main/7fbdbf_c9754d269f2c476c85ea0c9cc78fb805~mv2.webp)
- **Team Members**:  
  - Team Leader: Lin Jingjun (林靖鈞)  

---

## Project Overview

This project was developed for the AI CUP 2024 competition, which focused on predicting solar power generation using regional microclimate data. Our solution integrates advanced feature engineering techniques and a robust stacking regressor model to achieve state-of-the-art predictive performance, securing the top rank in the competition.

---

## Objectives

- **Accurate Predictions**: Leverage regional weather data to predict solar power output.  
- **Efficient Modeling**: Employ a stacking regression framework combining diverse base models.  
- **Innovative Strategies**: Enhance data diversity and model generalization using novel data augmentation methods.  
- **Scalable Application**: Provide insights for new plant site selection and performance assessment.  

---

## Environment Setup

- **Programming Language**: Python 3  
- **Development Environment**: Jupyter Notebook  
- **Operating System**: Ubuntu 24.04  
- **Required Libraries**:
  ```text
  numpy==1.24.3
  pandas==1.5.3
  matplotlib==3.7.1
  seaborn==0.12.2
  yellowbrick==1.5
  scikit-learn==1.2.2
  xgboost==1.7.6
  lightgbm==3.3.5
  catboost==1.2
  ```

### Hardware Configuration

- **Server**:  
  - **CPU**: AMD Ryzen 7 8845HS  
  - **RAM**: 64GB  
  - **GPU**: None  
- **Laptop**:  
  - **CPU**: AMD Ryzen 5 4600H  
  - **RAM**: 32GB  
  - **GPU**: None  

---

## Key Methodologies

### Data Processing

1. **Outlier Handling**: Remove anomalies based on typhoon and heavy rainfall data. Normalize critical features for stability.  
2. **Data Augmentation**: Use a novel "weather feature swapping" strategy to expand the training dataset from 110,000 to 750,000 samples.  
3. **Frequency Adjustment**:  
   - Training: Downsample to 10-minute intervals for noise reduction.  
   - Testing: Restore to minute-level granularity for precision.  
4. **Feature Engineering**:  
   - **Time-related Features**: Hour, minute, and periodic transformations (e.g., cosine/sine for day cycles).  
   - **Irradiance Metrics**: Statistical properties like mean, standard deviation, and normalization.

### Model Architecture

- **First Layer (Base Models)**:  
  - **RandomForest (RFRA)**: Trained with absolute error as the loss function, utilizing 1,000 trees.  
  - **HistGradientBoosting (HGBR)**: Optimized with histogram-based gradient boosting and early stopping.  
  - **CatBoost Regressor (CatBoostR)**: Supports categorical data natively and is order-insensitive.  
  - **LightGBM (LGBM)**: Configured with different loss functions for diverse data characteristics.  

- **Second Layer (Meta-Model)**:  
  - LightGBM with added randomness to enhance generalization.

### Innovative Techniques

- **Weather Feature Swapping**: Boosts data diversity and learns cross-location correlations effectively.  
- **Pseudo-Labeling**: Iteratively refines predictions by using prior predictions as pseudo-labels.  
- **Granular Time Usage**: Balances precision and efficiency by integrating low-noise training data and high-granularity testing data.

---

## Results and Insights

### Achievements

1. **Model Performance**:  
   - Achieved top leaderboard performance with a robust stacking regression model.  
   - Significantly improved prediction accuracy across varying weather conditions.  

2. **Innovative Contributions**:  
   - Introduced weather feature swapping to maximize the utilization of microclimate data.  
   - Designed a scalable prediction framework applicable to new power plants with no historical data.  

### Key Comparisons

- **Stacking vs. CNN-LSTM**:  
  - CNN-LSTM exhibited higher errors with increasing forecast time horizons.  
  - The stacking regressor model demonstrated superior overall accuracy and robustness.  

---

## How to Use

### Environment Setup

1. Install Python 3 and Conda.  
2. Create a virtual environment and install the required libraries:  
   ```bash
   conda create -n aicup python=3.8
   conda activate aicup
   pip install -r requirements.txt
   ```

### Execution Steps

1. **Data Preprocessing**: Run the data preparation script to clean and engineer features.  
2. **Model Training**: Train the stacking regressor model and save the results.  
3. **Evaluation**: Evaluate model performance and visualize the outcomes.

---

## Contact

- **Team Leader**: Lin Jingjun (林靖鈞)  
- **School**: National Chupei Senior High School (國立竹北高中普通科)  
- **Email**: xup6vu84m3ul6@gmail.com  

---

## License

This project is released for academic purposes only. For commercial use or redistribution, please contact the author for permission.

---

## References and External Resources

1. Tovar, M. et al. (2020). *PV Power Prediction using CNN-LSTM hybrid neural network model*.  
2. Himawari Satellite Data: [NOAA Himawari](https://registry.opendata.aws/noaa-himawari)  
3. Environmental Quality Data: [MOE](https://data.moenv.gov.tw/dataset/detail/AQX_P_35)  

For more details, refer to the competition report.

--- 
